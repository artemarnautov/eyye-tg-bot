# file: src/webapp_backend/cards_service.py
import logging
import os
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Tuple, Set

from supabase import Client

from .profile_service import get_interest_tags_for_user
from .openai_client import generate_cards_for_tags, is_configured as openai_is_configured

logger = logging.getLogger(__name__)

# ===================== –¢–µ–≥–∏ / —Ç–æ–ø–∏–∫–∏ =====================

MAX_BASE_TAGS = 4  # —Å–∫–æ–ª—å–∫–æ —Ç–µ–≥–æ–≤ –º–∞–∫—Å–∏–º—É–º –±–µ—Ä—ë–º –≤ –±–∞–∑–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä

# –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –Ω–∞–±–æ—Ä, –µ—Å–ª–∏ –ø—Ä–æ —é–∑–µ—Ä–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞–µ–º
DEFAULT_BASE_TAGS = ["entertainment", "society", "business", "politics"]


def build_base_tags_from_weights(user_rows: List[Dict[str, Any]]) -> Tuple[List[str], bool, Dict[str, Any]]:
    """
    user_rows: —Å–ø–∏—Å–æ–∫ dict —Å –∫–ª—é—á–∞–º–∏ 'tag' –∏ 'weight' –∏–∑ user_topic_weights.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (base_tags, used_default_tags, debug_info).
    """
    user_rows = user_rows or []
    debug_info: Dict[str, Any] = {
        "count": len(user_rows),
        "top": [],
    }

    if user_rows:
        # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–µ—Å–∞
        sorted_rows = sorted(
            (r for r in user_rows if r.get("tag")),
            key=lambda r: r.get("weight") or 0.0,
            reverse=True,
        )

        # –¥–ª—è debug.top –æ—Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—ã–µ 5
        debug_info["top"] = [
            [r["tag"], float(r.get("weight") or 0.0)] for r in sorted_rows[:5]
        ]

        personal_tags: List[str] = []

        # —Å–æ–±–∏—Ä–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º 1 —Å–ª–æ—Ç –ø–æ–¥ –æ–±—â–∏–µ)
        for r in sorted_rows:
            tag = r["tag"]
            if tag not in personal_tags:
                personal_tags.append(tag)
            if len(personal_tags) >= MAX_BASE_TAGS - 1:
                break

        base_tags: List[str] = []

        # —Å–Ω–∞—á–∞–ª–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ
        for tag in personal_tags:
            if len(base_tags) >= MAX_BASE_TAGS:
                break
            if tag not in base_tags:
                base_tags.append(tag)

        # –¥–æ–±–∏–≤–∞–µ–º –¥–æ MAX_BASE_TAGS –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏
        for tag in DEFAULT_BASE_TAGS:
            if len(base_tags) >= MAX_BASE_TAGS:
                break
            if tag not in base_tags:
                base_tags.append(tag)

        return base_tags, False, debug_info

    # –µ—Å–ª–∏ –ø–æ —é–∑–µ—Ä—É –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —á–∏—Å—Ç—ã–π –¥–µ—Ñ–æ–ª—Ç
    debug_info["top"] = []
    return DEFAULT_BASE_TAGS[:MAX_BASE_TAGS], True, debug_info


# ===================== –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∏–¥–∞ =====================

FEED_CARDS_LIMIT_DEFAULT = int(os.getenv("FEED_CARDS_LIMIT", "20"))

# "–°–≤–µ–∂–µ–µ" –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—á–∞—Å–æ–≤) ‚Äî –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 72 —á–∞—Å–∞ (3 –¥–Ω—è)
FEED_MAX_CARD_AGE_HOURS = int(os.getenv("FEED_MAX_CARD_AGE_HOURS", "72"))

LLM_CARD_GENERATION_ENABLED = (
    os.getenv("LLM_CARD_GENERATION_ENABLED", "true").lower() in ("1", "true", "yes")
)

DEFAULT_FEED_TAGS: List[str] = ["world_news", "business", "tech", "uk_students"]

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ä—Ç–æ—á–µ–∫, –∫–æ—Ç–æ—Ä–æ–µ –º—ã –≤–æ–æ–±—â–µ –≥–æ—Ç–æ–≤—ã —Ç–∞—â–∏—Ç—å –≤ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
FEED_MAX_FETCH_LIMIT = int(os.getenv("FEED_MAX_FETCH_LIMIT", "300"))

# –®–∏—Ä–æ–∫–æ–µ –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è "–¥–æ–±–æ—Ä–∞" –∫–∞—Ä—Ç–æ—á–µ–∫, –µ—Å–ª–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö FEED_MAX_CARD_AGE_HOURS –º–∞–ª–æ.
# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 30 –¥–Ω–µ–π (720 —á–∞—Å–æ–≤).
FEED_WIDE_AGE_HOURS = int(os.getenv("FEED_WIDE_AGE_HOURS", "720"))

# –ì–ª—É–±–æ–∫–æ–µ –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è all-time fallback (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ~1 –≥–æ–¥).
FEED_DEEP_AGE_HOURS = int(os.getenv("FEED_DEEP_AGE_HOURS", "8760"))

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å—Ç–æ LLM-–∫–∞—Ä—Ç–æ—á–µ–∫,
# –∫–æ–≥–¥–∞ —É –Ω–∞—Å –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞/–°–ú–ò.
DEFAULT_SOURCE_NAME = os.getenv("DEFAULT_SOURCE_NAME", "EYYE ‚Ä¢ AI-–ø–æ–¥–±–æ—Ä–∫–∞")

# ===================== –ü–∞–º—è—Ç—å –æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–∫–∞—Ö =====================

# –ß–µ—Ä–µ–∑ —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –º—ã –ø–µ—Ä–µ—Å—Ç–∞—ë–º —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏
FEED_SEEN_EXCLUDE_DAYS = int(os.getenv("FEED_SEEN_EXCLUDE_DAYS", "7"))

# –ì—Ä–µ–π—Å-–ø–µ—Ä–∏–æ–¥ –Ω–∞ "—Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é" (–º–∏–Ω—É—Ç—ã)
FEED_SEEN_SESSION_GRACE_MINUTES = int(
    os.getenv("FEED_SEEN_SESSION_GRACE_MINUTES", "30")
)

# –ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–æ–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ç–∞—â–∏–º –∑–∞ —Ä–∞–∑
FEED_SEEN_MAX_ROWS = int(os.getenv("FEED_SEEN_MAX_ROWS", "5000"))

# –°–∏–ª–∞ —Ä–∞–Ω–¥–æ–º–∞ –≤ —Å–∫–æ—Ä–µ (0.0‚Äì0.5; 0.15 ‚Äî –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ)
try:
    FEED_RANDOMNESS_STRENGTH = float(os.getenv("FEED_RANDOMNESS_STRENGTH", "0.15"))
except ValueError:
    FEED_RANDOMNESS_STRENGTH = 0.15

# ===================== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Wikipedia-–∏—Å—Ç–æ—á–Ω–∏–∫–∞ =====================

# –í –∫–∞–∫–æ–º –æ–∫–Ω–µ –ø–æ –¥–ª–∏–Ω–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –ª–µ–Ω—Ç—ã –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º –¥–æ–ª—é wiki-–∫–∞—Ä—Ç
WIKI_WINDOW_SIZE = int(os.getenv("FEED_WIKI_WINDOW_SIZE", "4"))
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ wiki-–∫–∞—Ä—Ç –≤ —ç—Ç–æ–º –æ–∫–Ω–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1 wiki –Ω–∞ 4 –∫–∞—Ä—Ç–æ—á–∫–∏)
WIKI_MAX_IN_WINDOW = int(os.getenv("FEED_WIKI_MAX_IN_WINDOW", "1"))

# ===================== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ =====================


def _safe_int_id(value: Any) -> int | None:
    if value is None:
        return None
    try:
        return int(value)
    except (TypeError, ValueError):
        return None


def _normalize_title_for_duplicate(title: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏:
    - –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä;
    - —É–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é;
    - —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ø—Ä–æ–±–µ–ª—ã.
    """
    if not title:
        return ""
    t = title.lower()
    # –≤—ã–∫–∏–¥—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    for ch in ",.!?;:¬´¬ª\"'()[]{}‚Äî‚Äì-":
        t = t.replace(ch, " ")
    t = " ".join(t.split())
    return t


def _extract_source_key(card: Dict[str, Any]) -> str:
    meta = card.get("meta") or {}
    src_type = (card.get("source_type") or "").strip().lower()

    # Wikipedia –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ (–∏–Ω–∞—á–µ –≤—Å—ë —Å–≤–∞–ª–∏—Ç—Å—è –≤ "EYYE ‚Ä¢ AI-–ø–æ–¥–±–æ—Ä–∫–∞")
    if src_type == "wikipedia":
        wiki_lang = (meta.get("wiki_lang") or "").strip() or "unknown"
        return f"wikipedia:{wiki_lang}"

    source_name = (meta.get("source_name") or "").strip()
    if source_name:
        return source_name

    src_ref = (card.get("source_ref") or "").strip()
    if src_type and src_ref:
        return f"{src_type}:{src_ref}"
    if src_type:
        return src_type
    if src_ref:
        return src_ref
    return "unknown"




def _extract_main_tag(card: Dict[str, Any], base_tags: List[str]) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–≥ –∫–∞—Ä—Ç–æ—á–∫–∏ ‚Äì –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–∞–º.
    –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –ø–æ—Ç–æ–º –ø–µ—Ä–≤—ã–π —Ç–µ–≥.
    """
    tags = card.get("tags") or []
    if not isinstance(tags, list):
        tags = []

    base_set = set(base_tags)
    for t in tags:
        if t in base_set:
            return t
    return tags[0] if tags else "unknown"


def _is_wikipedia_card(card: Dict[str, Any]) -> bool:
    """
    –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –∫–∞—Ä—Ç–æ—á–∫–∞ –∏–∑ Wikipedia.
    """
    src_type = (card.get("source_type") or "").strip().lower()
    return src_type == "wikipedia"


# ===================== –†–∞–±–æ—Ç–∞ —Å —Ç–∞–±–ª–∏—Ü–µ–π cards =====================


def _fetch_candidate_cards(
    supabase: Client,
    tags: List[str],
    limit: int,
    *,
    max_age_hours: int,
) -> List[Dict[str, Any]]:
    """
    –ë–µ—Ä—ë–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã cards:
    - —Ç–æ–ª—å–∫–æ is_active = true
    - —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–µ–∂–∏–µ (created_at >= now - max_age_hours), –µ—Å–ª–∏ max_age_hours > 0
    - –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–≥–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º overlaps(tags, tags_array).
    """
    if limit <= 0:
        return []

    now = datetime.now(timezone.utc)

    query = (
        supabase.table("cards")
        .select(
            "id,source_type,source_ref,title,body,tags,category,"
            "language,importance_score,created_at,is_active,meta"
        )
        .eq("is_active", True)
    )

    if max_age_hours > 0:
        min_created_at = now - timedelta(hours=max_age_hours)
        query = query.gte("created_at", min_created_at.isoformat())

    if tags:
        query = query.overlaps("tags", tags)

    try:
        resp = query.order("created_at", desc=True).limit(limit).execute()
    except Exception:
        logger.exception("Error fetching candidate cards from Supabase")
        return []

    data = getattr(resp, "data", None)
    if data is None:
        data = getattr(resp, "model", None)
    return data or []


# ===================== –ü–∞–º—è—Ç—å –æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–∫–∞—Ö =====================


def _load_seen_cards_for_user(
    supabase: Client,
    user_id: int,
) -> Dict[str, Any]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ user_seen_cards –≤—Å—ë, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–µ–ª –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ FEED_SEEN_EXCLUDE_DAYS.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º:
    {
      "rows": int,
      "exclude_ids": set[int],
      "recent_ids": set[int],
      "window_days": int,
      "grace_minutes": int,
      "error": Optional[str],
    }
    """
    result: Dict[str, Any] = {
        "rows": 0,
        "exclude_ids": set(),  # type: ignore[dict-item]
        "recent_ids": set(),  # type: ignore[dict-item]
        "window_days": FEED_SEEN_EXCLUDE_DAYS,
        "grace_minutes": FEED_SEEN_SESSION_GRACE_MINUTES,
        "error": None,
    }

    if supabase is None:
        result["error"] = "no_supabase"
        return result

    now = datetime.now(timezone.utc)
    window_cutoff = now - timedelta(days=FEED_SEEN_EXCLUDE_DAYS)
    grace_cutoff = now - timedelta(minutes=FEED_SEEN_SESSION_GRACE_MINUTES)

    try:
        resp = (
            supabase.table("user_seen_cards")
            .select("card_id, seen_at")
            .eq("user_id", user_id)
            .gte("seen_at", window_cutoff.isoformat())
            .limit(FEED_SEEN_MAX_ROWS)
            .execute()
        )
    except Exception:
        logger.exception("Error loading seen cards for user_id=%s", user_id)
        result["error"] = "load_failed"
        return result

    data = getattr(resp, "data", None)
    if data is None:
        data = getattr(resp, "model", None)
    rows = data or []

    exclude_ids: Set[int] = set()
    recent_ids: Set[int] = set()

    for row in rows:
        cid = _safe_int_id(row.get("card_id"))
        if cid is None:
            continue
        exclude_ids.add(cid)

        seen_at = row.get("seen_at")
        dt: datetime | None = None
        if isinstance(seen_at, str):
            try:
                dt = datetime.fromisoformat(seen_at.replace("Z", "+00:00"))
            except Exception:
                dt = None
        if dt and dt >= grace_cutoff:
            recent_ids.add(cid)

    result["rows"] = len(rows)
    result["exclude_ids"] = exclude_ids
    result["recent_ids"] = recent_ids
    return result


def _load_user_topic_weights(
    supabase: Client | None,
    user_id: int,
) -> Tuple[Dict[str, float], List[Dict[str, Any]]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ —Ç–µ–≥–∞–º –∏–∑ user_topic_weights.
    tg_id –≤ —Ç–∞–±–ª–∏—Ü–µ = user_id (Telegram ID).

    –í–æ–∑–≤—Ä–∞—â–∞–µ–º:
      - weights: {tag -> weight}
      - rows: —Å—ã—Ä—ã–µ —Å—Ç—Ä–æ–∫–∏ [{"tag": ..., "weight": ...}, ...] ‚Äî –∏—Ö –±—É–¥–µ–º
        –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ build_base_tags_from_weights.
    """
    weights: Dict[str, float] = {}
    rows: List[Dict[str, Any]] = []

    if supabase is None:
        return weights, rows

    try:
        resp = (
            supabase.table("user_topic_weights")
            .select("tag,weight")
            .eq("tg_id", user_id)
            .execute()
        )
    except Exception:
        logger.exception("Error loading user_topic_weights for user_id=%s", user_id)
        return weights, rows

    data = getattr(resp, "data", None)
    if data is None:
        data = getattr(resp, "model", None)

    rows = list(data or [])

    for row in rows:
        tag = str(row.get("tag") or "").strip()
        if not tag:
            continue
        try:
            w = float(row.get("weight") or 0.0)
        except (TypeError, ValueError):
            w = 0.0
        weights[tag] = w

    return weights, rows


def _mark_cards_as_seen(
    supabase: Client | None,
    user_id: int,
    cards: List[Dict[str, Any]],
) -> int:
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–∫—Ç –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∫–∞—Ä—Ç–æ—á–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –≤ user_seen_cards.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ (–ø–æ –¥–∞–Ω–Ω—ã–º Supabase).
    """
    if supabase is None or not cards:
        return 0

    now = datetime.now(timezone.utc).isoformat()
    payload: List[Dict[str, Any]] = []

    for card in cards:
        cid = _safe_int_id(card.get("id"))
        if cid is None:
            continue
        payload.append(
            {
                "user_id": user_id,
                "card_id": cid,
                "seen_at": now,
            }
        )

    if not payload:
        return 0

    try:
        # –û–±—ã—á–Ω–æ Supabase –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏,
        # –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞.
        resp = supabase.table("user_seen_cards").insert(payload).execute()
    except Exception:
        logger.exception("Error inserting user_seen_cards for user_id=%s", user_id)
        return 0

    data = getattr(resp, "data", None)
    if data is None:
        data = getattr(resp, "model", None)

    if isinstance(data, list):
        inserted = len(data)
    else:
        # –µ—Å–ª–∏ –≤–µ—Ä–Ω—É–ª–∏ —á—Ç–æ-—Ç–æ –∏–Ω–æ–µ (–∏–ª–∏ returning=minimal) ‚Äì —Å—á–∏—Ç–∞–µ–º –ø–æ payload
        inserted = len(payload)

    logger.info(
        "Marked %d cards as seen for user_id=%s (payload=%d)",
        inserted,
        user_id,
        len(payload),
    )
    return inserted


# ===================== –°–∫–æ—Ä–∏–Ω–≥ –∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ =====================


def _score_cards_for_user(
    cards: List[Dict[str, Any]],
    base_tags: List[str],
    user_id: int | None = None,
    user_topic_weights: Dict[str, float] | None = None,
) -> List[Dict[str, Any]]:
    """
    TikTok-lite —Å–∫–æ—Ä–∏–Ω–≥:
    - importance_score (–±–∞–∑–æ–≤—ã–π –≤–µ—Å –∫–∞—Ä—Ç–æ—á–∫–∏)
    - –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –ø–æ —Ç–µ–≥–∞–º –∏–∑ user_topic_weights
    - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ —Å –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
    - —Å–≤–µ–∂–µ—Å—Ç—å
    - –ª—ë–≥–∫–∏–π –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–Ω–¥–æ–º
    """
    now = datetime.now(timezone.utc)
    base_tag_set = set(base_tags)
    today_str = now.strftime("%Y-%m-%d")
    topic_weights = user_topic_weights or {}

    scored: List[Tuple[float, Dict[str, Any]]] = []

    for card in cards:
        card_tags = card.get("tags") or []
        if not isinstance(card_tags, list):
            card_tags = []

        try:
            importance = float(card.get("importance_score") or 1.0)
        except (TypeError, ValueError):
            importance = 1.0

        # –°–∏–≥–Ω–∞–ª –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –≤–µ—Å–∞–º —Ç–µ–≥–æ–≤ (user_topic_weights)
        interest_score = 0.0
        for t in card_tags:
            interest_score += float(topic_weights.get(t, 0.0))

        # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Ç–µ–≥–∞–º–∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ (–ø—Ä–æ—Å—Ç–æ–π fallback)
        overlap_count = sum(1 for t in card_tags if t in base_tag_set)
        overlap_bonus = 0.3 * overlap_count

        # –ë–æ–Ω—É—Å –∑–∞ —Å–≤–µ–∂–µ—Å—Ç—å (0..1)
        recency_score = 0.0
        created_at = card.get("created_at")
        if isinstance(created_at, str):
            try:
                dt = datetime.fromisoformat(created_at.replace("Z", "+00:00"))
                age_hours = (now - dt).total_seconds() / 3600.0
                if age_hours < FEED_MAX_CARD_AGE_HOURS:
                    recency_score = (
                        FEED_MAX_CARD_AGE_HOURS - age_hours
                    ) / FEED_MAX_CARD_AGE_HOURS
                else:
                    recency_score = 0.0
            except Exception:
                recency_score = 0.0

        # –õ—ë–≥–∫–∏–π –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–Ω–¥–æ–º –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –∫–∞—Ä—Ç–æ—á–∫–∏
        rand_bonus = 0.0
        if FEED_RANDOMNESS_STRENGTH > 0.0:
            cid = _safe_int_id(card.get("id")) or 0
            uid = int(user_id or 0)
            seed_str = f"{uid}:{cid}:{today_str}"
            h = hashlib.sha256(seed_str.encode("utf-8")).digest()
            # –ó–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
            value = int.from_bytes(h[:4], "big") / float(2**32 - 1)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ [-1, 1] –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
            rand_bonus = (value * 2.0 - 1.0) * FEED_RANDOMNESS_STRENGTH

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä: –∏–Ω—Ç–µ—Ä–µ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç,
        # importance –∏ —Å–≤–µ–∂–µ—Å—Ç—å ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã.
        score = (
            importance
            + 1.5 * interest_score
            + overlap_bonus
            + recency_score
            + rand_bonus
        )
        scored.append((score, card))

    scored.sort(key=lambda x: x[0], reverse=True)
    return [c for score, c in scored]


def _apply_dedup_and_diversity(
    ranked: List[Dict[str, Any]],
    base_tags: List[str],
    max_consecutive_source: int = 2,
    max_consecutive_tag: int = 2,
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞:
    - —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º;
    - —Å—Ç–∞—Ä–∞–µ–º—Å—è —Ä–∞–∑–≤–µ—Å—Ç–∏ –∫–∞—Ä—Ç–æ—á–∫–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏ –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–≥–∞–º;
    - –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º –¥–æ–ª—é Wikipedia-–∫–∞—Ä—Ç–æ—á–µ–∫:
      –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –±–æ–ª–µ–µ 1 wiki-–∫–∞—Ä—Ç–æ—á–∫–∏ –≤ –æ–∫–Ω–µ –∏–∑ 4 –ø–æ–¥—Ä—è–¥ (‚âà 25% –ª–µ–Ω—Ç—ã –ª–æ–∫–∞–ª—å–Ω–æ);
    - –ù–û –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é, –∞ —Å–Ω–∞—á–∞–ª–∞ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º
      –∏ –ø—ã—Ç–∞–µ–º—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ, –∑–∞—Ç–µ–º ‚Äî –≤ —Ö–≤–æ—Å—Ç.

    –í–∞–∂–Ω–æ: –¥—É–±–ª—è–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º –≤—Å—ë —Ä–∞–≤–Ω–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ –ø–æ–ø–∞–¥–∞—Ç—å –≤ –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫.
    """
    if not ranked:
        return [], {
            "initial": 0,
            "after_dedup_and_diversity": 0,
            "removed_as_duplicates": 0,
            "deferred_count": 0,
            "used_deferred": 0,
            "tail_added": 0,
            "total_ranked_raw": 0,
            "wiki_window_size": WIKI_WINDOW_SIZE,
            "wiki_max_in_window": WIKI_MAX_IN_WINDOW,
        }

    total_ranked_raw = len(ranked)

    seen_titles: Set[str] = set()
    selected: List[Dict[str, Any]] = []
    deferred: List[Dict[str, Any]] = []
    removed_duplicates = 0

    def violates_diversity(
        current: List[Dict[str, Any]],
        source_key: str,
        main_tag: str,
        card: Dict[str, Any],
    ) -> bool:
        window = current[-4:]
        same_source = 0
        same_tag = 0
        for c in window:
            if _extract_source_key(c) == source_key:
                same_source += 1
            if _extract_main_tag(c, base_tags) == main_tag:
                same_tag += 1

        if same_source >= max_consecutive_source or same_tag >= max_consecutive_tag:
            return True

        # Wiki-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö WIKI_WINDOW_SIZE –∫–∞—Ä—Ç–æ—á–∫–∞—Ö –Ω–µ –±–æ–ª–µ–µ WIKI_MAX_IN_WINDOW wiki-–∫–∞—Ä—Ç
        if _is_wikipedia_card(card) and WIKI_WINDOW_SIZE > 0:
            wiki_window = current[-WIKI_WINDOW_SIZE:]
            wiki_count = 0
            for c in wiki_window:
                if _is_wikipedia_card(c):
                    wiki_count += 1
            if wiki_count >= WIKI_MAX_IN_WINDOW:
                return True

        return False

    # 1) –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: –¥–µ–¥—É–ø –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º + –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è "–∑–¥–µ—Å—å –∏ —Å–µ–π—á–∞—Å"
    for card in ranked:
        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)

        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue

        source_key = _extract_source_key(card)
        main_tag = _extract_main_tag(card, base_tags)

        if violates_diversity(selected, source_key, main_tag, card):
            deferred.append(card)
            continue

        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)

    # 2) –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø—Ä–æ–±—É–µ–º –¥–æ–º–µ—à–∞—Ç—å deferred
    still_deferred: List[Dict[str, Any]] = []
    used_deferred = 0

    for card in deferred:
        source_key = _extract_source_key(card)
        main_tag = _extract_main_tag(card, base_tags)

        if violates_diversity(selected, source_key, main_tag, card):
            still_deferred.append(card)
            continue

        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)
        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue

        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)
        used_deferred += 1

    # 3) –¢—Ä–µ—Ç–∏–π –ø—Ä–æ—Ö–æ–¥: —Ö–≤–æ—Å—Ç.
    # –†–∞—Å—Å–ª–∞–±–ª—è–µ–º source/tag, –ù–û –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º 2 wiki –ø–æ–¥—Ä—è–¥, –µ—Å–ª–∏ –µ—Å—Ç—å —á–µ–º —Ä–∞–∑–±–∞–≤–∏—Ç—å.
    tail_queue = list(still_deferred)
    tail_added = 0
    rotations = 0
    max_rotations = max(len(tail_queue) * 2, 50)

    while tail_queue and rotations < max_rotations:
        card = tail_queue.pop(0)

        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)
        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue

        # üö´ –∑–∞–ø—Ä–µ—Ç wiki-wiki –ø–æ–¥—Ä—è–¥ (–µ—Å–ª–∏ –º–æ–∂–Ω–æ ‚Äî –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –≤ –∫–æ–Ω–µ—Ü –æ—á–µ—Ä–µ–¥–∏)
        if selected and _is_wikipedia_card(selected[-1]) and _is_wikipedia_card(card):
            tail_queue.append(card)
            rotations += 1
            continue

        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)
        tail_added += 1
        rotations = 0  # –µ—Å—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å ‚Äî —Å–±—Ä–æ—Å

    # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –∫–∞—Ä—Ç–æ—á–∫–∏ (–æ–±—ã—á–Ω–æ –∫–æ–≥–¥–∞ –æ—Å—Ç–∞–ª–∏—Å—å —Ç–æ–ª—å–∫–æ wiki) ‚Äî –¥–æ–∫–∏–¥—ã–≤–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–π fallback)
    for card in tail_queue:
        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)
        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue
        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)
        tail_added += 1

    debug_postprocess = {
        "initial": total_ranked_raw,
        "after_dedup_and_diversity": len(selected),
        "removed_as_duplicates": removed_duplicates,
        "deferred_count": len(deferred),
        "used_deferred": used_deferred,
        "tail_added": tail_added,
        "total_ranked_raw": total_ranked_raw,
        "wiki_window_size": WIKI_WINDOW_SIZE,
        "wiki_max_in_window": WIKI_MAX_IN_WINDOW,
    }

    return selected, debug_postprocess


    def violates_diversity(
        current: List[Dict[str, Any]],
        source_key: str,
        main_tag: str,
        card: Dict[str, Any],
    ) -> bool:
        # –°–º–æ—Ç—Ä–∏–º –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞—Ä—Ç–æ—á–µ–∫
        window = current[-4:]
        same_source = 0
        same_tag = 0
        for c in window:
            if _extract_source_key(c) == source_key:
                same_source += 1
            if _extract_main_tag(c, base_tags) == main_tag:
                same_tag += 1

        if same_source >= max_consecutive_source or same_tag >= max_consecutive_tag:
            return True

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ –¥–ª—è Wikipedia:
        # —Å—Ä–µ–¥–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö WIKI_WINDOW_SIZE –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ
        # WIKI_MAX_IN_WINDOW wiki-–∫–∞—Ä—Ç.
        if _is_wikipedia_card(card) and WIKI_WINDOW_SIZE > 0:
            wiki_window = current[-WIKI_WINDOW_SIZE:]
            wiki_count = 0
            for c in wiki_window:
                if _is_wikipedia_card(c):
                    wiki_count += 1
            if wiki_count >= WIKI_MAX_IN_WINDOW:
                return True

        return False

    # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: –æ—Ç–±–∏—Ä–∞–µ–º –≤—Å—ë, —á—Ç–æ:
    # - –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É;
    # - –Ω–µ –ª–æ–º–∞–µ—Ç –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é "–∑–¥–µ—Å—å –∏ —Å–µ–π—á–∞—Å".
    for card in ranked:
        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)

        # –ñ—ë—Å—Ç–∫–∏–π –¥–µ–¥—É–ø –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue

        source_key = _extract_source_key(card)
        main_tag = _extract_main_tag(card, base_tags)

        if violates_diversity(selected, source_key, main_tag, card):
            # –û—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º, –ø–æ–ø—Ä–æ–±—É–µ–º –≤—Å—Ç–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ
            deferred.append(card)
            continue

        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)

    # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø—Ä–æ–±—É–µ–º –¥–æ–º–µ—à–∞—Ç—å –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏
    still_deferred: List[Dict[str, Any]] = []
    used_deferred = 0

    for card in deferred:
        source_key = _extract_source_key(card)
        main_tag = _extract_main_tag(card, base_tags)

        if violates_diversity(selected, source_key, main_tag, card):
            # –í—Å—ë –µ—â—ë –ª–æ–º–∞–µ—Ç –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é ‚Äì –ø–æ–∫–∞ –¥–µ—Ä–∂–∏–º –æ—Ç–¥–µ–ª—å–Ω–æ
            still_deferred.append(card)
            continue

        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)
        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue

        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)
        used_deferred += 1

    # –¢—Ä–µ—Ç–∏–π –ø—Ä–æ—Ö–æ–¥: –≤—Å—ë, —á—Ç–æ —Ç–∞–∫ –∏ –Ω–µ –≤–ø–∏—Å–∞–ª–æ—Å—å –ø–æ "–∫—Ä–∞—Å–æ—Ç–µ",
    # –ø—Ä–æ—Å—Ç–æ –¥–æ–∫–∏–¥—ã–≤–∞–µ–º –≤ —Ö–≤–æ—Å—Ç (–∫—Ä–æ–º–µ –¥—É–±–ª–µ–π –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º).
    # –ó–¥–µ—Å—å –º—ã —É–∂–µ –ù–ï –ø—Ä–∏–º–µ–Ω—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É/—Ç–µ–≥–∞–º,
    # –Ω–æ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É —Å–æ–±–ª—é–¥–∞–µ–º –¥–µ–¥—É–ø –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º.
    tail_added = 0
    for card in still_deferred:
        title = (card.get("title") or "").strip()
        norm_title = _normalize_title_for_duplicate(title)
        if norm_title and norm_title in seen_titles:
            removed_duplicates += 1
            continue

        selected.append(card)
        if norm_title:
            seen_titles.add(norm_title)
        tail_added += 1

    debug_postprocess = {
        "initial": total_ranked_raw,
        "after_dedup_and_diversity": len(selected),
        "removed_as_duplicates": removed_duplicates,
        "deferred_count": len(deferred),
        "used_deferred": used_deferred,
        "tail_added": tail_added,
        "total_ranked_raw": total_ranked_raw,
        "wiki_window_size": WIKI_WINDOW_SIZE,
        "wiki_max_in_window": WIKI_MAX_IN_WINDOW,
    }

    return selected, debug_postprocess


# ===================== –í—Å—Ç–∞–≤–∫–∞ LLM-–∫–∞—Ä—Ç–æ—á–µ–∫ –≤ DB =====================


def _insert_cards_into_db(
    supabase: Client,
    cards: List[Dict[str, Any]],
    *,
    language: str | None = "ru",
    source_type: str = "llm",
    fallback_source_name: str | None = None,
    source_ref: str | None = None,
) -> List[Dict[str, Any]]:
    """
    –í—Å—Ç–∞–≤–ª—è–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ/–ø–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü—É cards.

    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞:
    1) c["source_name"] / c["source"] / c["channel_name"], –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞.
    2) fallback_source_name (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª–∞, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã —Å–ø–∞—Ä—Å–∏–ª–∏ –ø–æ—Å—Ç).
    3) DEFAULT_SOURCE_NAME ("EYYE ‚Ä¢ AI-–ø–æ–¥–±–æ—Ä–∫–∞") ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.

    language / source_type / source_ref:
    - language: —è–∑—ã–∫ –∫–∞—Ä—Ç–æ—á–∫–∏ ("ru", "en", ...) ‚Äî –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
      –∏–ª–∏ –ø–æ–ª–æ–∂–∏—Ç—å –≤ —Å–∞–º—É –∫–∞—Ä—Ç–æ—á–∫—É c["language"].
    - source_type: "telegram", "rss", "llm", "wikipedia" –∏ —Ç.–ø.
    - source_ref: –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å—Å—ã–ª–∫–∞ –∏–ª–∏ message_id –∫–∞–Ω–∞–ª–∞.
    """
    if not cards:
        return []

    payload: List[Dict[str, Any]] = []

    # –Ø–∑—ã–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –≤ —Å–∞–º–æ–π –∫–∞—Ä—Ç–æ—á–∫–µ –Ω–µ —É–∫–∞–∑–∞–Ω
    default_lang: str | None
    if isinstance(language, str):
        default_lang = language.strip() or None
    else:
        default_lang = None

    for c in cards:
        title = (c.get("title") or "").strip()
        body = (c.get("body") or "").strip()
        tags = c.get("tags") or []
        if not isinstance(tags, list):
            tags = [str(tags)]

        if not title or not body:
            continue

        try:
            importance = float(c.get("importance_score", 1.0))
        except (TypeError, ValueError):
            importance = 1.0

        # 1) –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ / –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        raw_source_name = (
            c.get("source_name")
            or c.get("source")
            or c.get("channel_name")
            or c.get("channel_title")
        )

        # 2) –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–∏—á–µ–≥–æ –Ω–µ –¥–∞–ª–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback_source_name
        if not raw_source_name and fallback_source_name:
            raw_source_name = fallback_source_name

        # 3) –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ LLM
        if not raw_source_name:
            raw_source_name = DEFAULT_SOURCE_NAME

        source_name = str(raw_source_name).strip()

        # –ï—Å–ª–∏ —É —Å–∞–º–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏ –µ—Å—Ç—å source_ref/url ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å
        card_source_ref = c.get("source_ref") or c.get("url") or c.get("link")
        final_source_ref = source_ref or card_source_ref

        # –Ø–∑—ã–∫ –∫–∞—Ä—Ç–æ—á–∫–∏: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ —Å–∞–º–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏, –ø–æ—Ç–æ–º –¥–µ—Ñ–æ–ª—Ç, –ø–æ—Ç–æ–º "ru"
        card_lang_raw = c.get("language")
        if isinstance(card_lang_raw, str):
            card_lang = card_lang_raw.strip() or None
        else:
            card_lang = None
        final_language = card_lang or default_lang or "ru"

        meta: Dict[str, Any] = {
            "source_name": source_name,
        }

        payload.append(
            {
                "title": title,
                "body": body,
                "tags": [str(t).strip() for t in tags if t],
                "importance_score": importance,
                "is_active": True,
                "source_type": source_type,
                "source_ref": final_source_ref,
                "language": final_language,
                "meta": meta,
            }
        )

    if not payload:
        return []

    try:
        resp = supabase.table("cards").insert(payload).execute()
    except Exception:
        logger.exception("Error inserting generated cards into Supabase")
        return []

    data = getattr(resp, "data", None)
    if data is None:
        data = getattr(resp, "model", None)
    data = data or []
    logger.info("Inserted %d generated cards into DB", len(data))
    return data


# ===================== –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–¥–∞ =====================


def build_feed_for_user(
    supabase: Client | None,
    user_id: int,
    limit: int | None = None,
    offset: int = 0,
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è /api/feed.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - items: —Å–ø–∏—Å–æ–∫ –∫–∞—Ä—Ç–æ—á–µ–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —É—á—ë—Ç–æ–º offset/limit)
    - debug: –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.
    """
    debug: Dict[str, Any] = {
        "offset": offset,
    }

    if supabase is None:
        debug["reason"] = "no_supabase"
        debug["base_tags"] = []
        debug["limit"] = limit or FEED_CARDS_LIMIT_DEFAULT
        debug["total_candidates"] = 0
        debug["returned"] = 0
        debug["has_more"] = False
        debug["next_offset"] = None
        debug["seen"] = {
            "rows": 0,
            "exclude_ids": 0,
            "recent_ids": 0,
            "window_days": FEED_SEEN_EXCLUDE_DAYS,
            "grace_minutes": FEED_SEEN_SESSION_GRACE_MINUTES,
            "error": "no_supabase",
            "relaxed": False,
            "marked": 0,
        }
        return [], debug

    # --- –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º offset/limit ---
    try:
        offset = int(offset)
    except (TypeError, ValueError):
        offset = 0
    if offset < 0:
        offset = 0

    if limit is None or limit <= 0:
        limit = FEED_CARDS_LIMIT_DEFAULT
    limit = min(max(int(limit), 1), 50)
    debug["limit"] = limit
    page_index = offset // limit
    debug["page_index"] = page_index

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ —Ç–µ–≥–∞–º (user_topic_weights) + base_tags
    user_topic_weights, user_topic_rows = _load_user_topic_weights(supabase, user_id)

    base_tags: List[str] = []
    used_default_tags = False

    if user_topic_rows:
        # –ï—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –ø–æ —Ç–µ–≥–∞–º ‚Äî —Å—Ç—Ä–æ–∏–º base_tags –∏–∑ –Ω–∏—Ö
        base_tags, used_default_tags_from_builder, user_topics_debug = (
            build_base_tags_from_weights(user_topic_rows)
        )
        used_default_tags = used_default_tags_from_builder
    else:
        # –ù–µ—Ç –≤–µ—Å–æ–≤ (–Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–Ω–±–æ—Ä–¥–∏–Ω–≥ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç
        base_tags = get_interest_tags_for_user(supabase, user_id)
        if not base_tags:
            base_tags = DEFAULT_FEED_TAGS
            used_default_tags = True

        if user_topic_weights:
            sorted_items = sorted(
                user_topic_weights.items(), key=lambda kv: kv[1], reverse=True
            )
            user_topics_debug = {
                "count": len(user_topic_weights),
                "top": sorted_items[:20],
            }
        else:
            user_topics_debug = {
                "count": 0,
                "top": [],
            }

    debug["base_tags"] = base_tags
    debug["used_default_tags"] = used_default_tags
    debug["user_topic_weights"] = user_topics_debug

    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏
    seen_info = _load_seen_cards_for_user(supabase, user_id)
    exclude_ids: Set[int] = seen_info.get("exclude_ids") or set()
    recent_ids: Set[int] = seen_info.get("recent_ids") or set()

    debug["seen"] = {
        "rows": int(seen_info.get("rows") or 0),
        "exclude_ids": len(exclude_ids),
        "recent_ids": len(recent_ids),
        "window_days": FEED_SEEN_EXCLUDE_DAYS,
        "grace_minutes": FEED_SEEN_SESSION_GRACE_MINUTES,
        "error": seen_info.get("error"),
        "relaxed": False,
        "marked": 0,
    }

    # 3. –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ "—Å–ª–æ—è–º–∏" (tiered fallback)
    # –ë–µ—Ä—ë–º —Å –∑–∞–ø–∞—Å–æ–º: (limit + offset) * 3, —á—Ç–æ–±—ã —Ö–≤–∞—Ç–∏–ª–æ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫ offset.
    fetch_limit = (limit + offset) * 3
    fetch_limit = max(fetch_limit, limit)  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    fetch_limit = min(fetch_limit, FEED_MAX_FETCH_LIMIT)

    mixed_tags = sorted({*base_tags, *DEFAULT_FEED_TAGS})

    phases_config: List[Dict[str, Any]] = []

    # –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏, —Å–≤–µ–∂–µ–µ –æ–∫–Ω–æ
    phases_config.append(
        {
            "stage": "personal_recent",
            "tags": base_tags,
            "age_hours": FEED_MAX_CARD_AGE_HOURS,
        }
    )

    # –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏, —à–∏—Ä–æ–∫–æ–µ –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    if FEED_WIDE_AGE_HOURS > FEED_MAX_CARD_AGE_HOURS:
        phases_config.append(
            {
                "stage": "personal_wide",
                "tags": base_tags,
                "age_hours": FEED_WIDE_AGE_HOURS,
            }
        )

    # –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ + –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —Ç–µ–≥–∏
    if mixed_tags and mixed_tags != base_tags:
        phases_config.append(
            {
                "stage": "mixed_recent",
                "tags": mixed_tags,
                "age_hours": FEED_MAX_CARD_AGE_HOURS,
            }
        )
        phases_config.append(
            {
                "stage": "mixed_wide",
                "tags": mixed_tags,
                "age_hours": FEED_WIDE_AGE_HOURS,
            }
        )

    candidates_by_id: Dict[str, Dict[str, Any]] = {}
    phases_debug: List[Dict[str, Any]] = []

    def _run_phases(phases: List[Dict[str, Any]], label: str) -> None:
        nonlocal candidates_by_id, phases_debug
        for phase in phases:
            if len(candidates_by_id) >= fetch_limit:
                break

            tags = phase.get("tags") or []
            age_hours = int(phase.get("age_hours") or 0)
            stage_name = phase.get("stage") or "unknown"

            remaining = fetch_limit - len(candidates_by_id)
            if remaining <= 0:
                break

            # –§–∞–∑—ã –±–µ–∑ —Ç–µ–≥–æ–≤ —Å—á–∏—Ç–∞–µ–º —è–≤–Ω—ã–º fallback (label="fallback"),
            # –ø–æ—ç—Ç–æ–º—É –≤ initial-—Ä–∞—É–Ω–¥–µ –º—ã –∏—Ö –Ω–µ –∑–∞–¥–∞—ë–º.
            if label == "initial" and not tags:
                phases_debug.append(
                    {
                        "stage": stage_name,
                        "label": label,
                        "tags_count": 0,
                        "age_hours": age_hours,
                        "fetched": 0,
                        "skipped": True,
                    }
                )
                continue

            fetched = _fetch_candidate_cards(
                supabase=supabase,
                tags=tags,
                limit=remaining,
                max_age_hours=age_hours,
            )

            for card in fetched:
                cid = card.get("id")
                if cid is None:
                    continue
                key = str(cid)
                if key not in candidates_by_id:
                    candidates_by_id[key] = card

            phases_debug.append(
                {
                    "stage": stage_name,
                    "label": label,
                    "tags_count": len(tags),
                    "age_hours": age_hours,
                    "fetched": len(fetched),
                    "unique_after_phase": len(candidates_by_id),
                }
            )

    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∑—ã (–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —Ç–µ–≥–∏)
    _run_phases(phases_config, label="initial")

    candidates_all: List[Dict[str, Any]] = list(candidates_by_id.values())
    total_candidates_raw = len(candidates_all)
    debug["phases"] = phases_debug
    debug["total_candidates_raw_initial"] = total_candidates_raw

    required_for_page = offset + limit

    # 3.1. –ï—Å–ª–∏ –¥–∞–∂–µ –≤ —à–∏—Ä–æ–∫–æ–º –æ–∫–Ω–µ –ø–æ —Ç–µ–≥–∞–º –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî
    # –¥–æ–±–∞–≤–ª—è–µ–º fallback-—Ñ–∞–∑—ã "–ª—é–±–æ–π —Ç–µ–≥".
    if total_candidates_raw < required_for_page and total_candidates_raw < fetch_limit:
        fallback_phases: List[Dict[str, Any]] = []

        # –õ—é–±—ã–µ —Ç–µ–≥–∏, —à–∏—Ä–æ–∫–æ–µ –æ–∫–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 30 –¥–Ω–µ–π)
        fallback_phases.append(
            {
                "stage": "any_recent_wide",
                "tags": [],
                "age_hours": FEED_WIDE_AGE_HOURS,
            }
        )

        # –õ—é–±—ã–µ —Ç–µ–≥–∏, –≤–æ–æ–±—â–µ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        deep_hours = FEED_DEEP_AGE_HOURS if FEED_DEEP_AGE_HOURS > 0 else 0
        fallback_phases.append(
            {
                "stage": "any_all_time",
                "tags": [],
                "age_hours": deep_hours,
            }
        )

        _run_phases(fallback_phases, label="fallback")

        candidates_all = list(candidates_by_id.values())
        total_candidates_raw = len(candidates_all)
        debug["total_candidates_raw_after_fallback"] = total_candidates_raw
    else:
        debug["total_candidates_raw_after_fallback"] = total_candidates_raw

    debug["total_candidates_raw"] = total_candidates_raw

    # 4. –ï—Å–ª–∏ –≤ –ë–î –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏ —á–µ—Ä–µ–∑ OpenAI.
    if total_candidates_raw == 0:
        if LLM_CARD_GENERATION_ENABLED and openai_is_configured():
            need_count = max(required_for_page * 2, 20)
            logger.info(
                "No cards in DB for user_id=%s. Generating ~%d cards via OpenAI.",
                user_id,
                need_count,
            )
            generated = generate_cards_for_tags(
                tags=base_tags,
                language="ru",
                count=need_count,
            )
            if generated:
                inserted = _insert_cards_into_db(
                    supabase,
                    generated,
                    language="ru",
                    source_type="llm",
                )
                candidates_all = inserted or []
                total_candidates_raw = len(candidates_all)
                debug["reason"] = "generated_via_openai"
                debug["generated"] = total_candidates_raw
            else:
                debug["reason"] = "no_cards"
                debug["returned"] = 0
                debug["has_more"] = False
                debug["next_offset"] = None
                return [], debug
        else:
            debug["reason"] = "no_cards"
            debug["returned"] = 0
            debug["has_more"] = False
            debug["next_offset"] = None
            return [], debug
    else:
        debug["reason"] = "cards_from_db"

    # 5. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫.
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ—Ç–¥–∞—Ç—å —Ç–æ–ª—å–∫–æ "unseen", –Ω–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–∂–µ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî
    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å –ø—É–ª (–≤–∫–ª—é—á–∞—è seen), —á—Ç–æ–±—ã –ª–µ–Ω—Ç–∞ –Ω–µ –æ–±—Ä—ã–≤–∞–ª–∞—Å—å.
    if exclude_ids:
        unseen: List[Dict[str, Any]] = []
        for c in candidates_all:
            cid = _safe_int_id(c.get("id"))
            if cid is None or cid not in exclude_ids:
                unseen.append(c)
        unseen_count = len(unseen)
    else:
        unseen = list(candidates_all)
        unseen_count = len(unseen)

    debug["removed_seen"] = total_candidates_raw - unseen_count

    if unseen_count >= required_for_page:
        # unseen-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äì –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö.
        candidates = unseen
        debug["seen"]["relaxed"] = False
    else:
        # unseen –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äì –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å –ø—É–ª –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (seen + unseen).
        candidates = candidates_all
        debug["seen"]["relaxed"] = True

    total_candidates = len(candidates)
    debug["total_candidates"] = total_candidates

    # 6. –†–∞–Ω–∂–∏—Ä—É–µ–º (TikTok-lite) –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –¥–µ–¥—É–ø/–¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
    ranked_raw = _score_cards_for_user(
        candidates,
        base_tags,
        user_id=user_id,
        user_topic_weights=user_topic_weights,
    )
    ranked, postprocess_debug = _apply_dedup_and_diversity(ranked_raw, base_tags)
    debug["postprocess"] = postprocess_debug

    total_ranked = len(ranked)
    debug["total_ranked"] = total_ranked

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤–æ –≤—Å—ë–º ranked
    source_counts: Dict[str, int] = {}
    wiki_count_total = 0
    for c in ranked:
        src = (c.get("source_type") or "unknown").lower()
        source_counts[src] = source_counts.get(src, 0) + 1
        if _is_wikipedia_card(c):
            wiki_count_total += 1
    debug["sources_ranked"] = source_counts
    debug["wiki_count_ranked"] = wiki_count_total

    if total_ranked == 0:
        debug["reason"] = "no_ranked_cards"
        debug["returned"] = 0
        debug["has_more"] = False
        debug["next_offset"] = None
        return [], debug

    # 7. –ü–∞–≥–∏–Ω–∞—Ü–∏—è –ø–æ offset/limit + wrap-around fallback –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤.
    if offset < total_ranked:
        start = offset
        end = min(start + limit, total_ranked)
        page = ranked[start:end]
        has_more = total_ranked > end
        next_offset = end if has_more else None
        debug["pagination_mode"] = "linear"
    else:
        # offset –≤—ã—à–µ–ª –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫ ‚Äì –≤–∫–ª—é—á–∞–µ–º "–∫—Ä—É–≥–æ–≤—É—é" –ø–∞–≥–∏–Ω–∞—Ü–∏—é,
        # —á—Ç–æ–±—ã –ª–µ–Ω—Ç–∞ –Ω–µ –æ–±—Ä—ã–≤–∞–ª–∞—Å—å –¥–∞–∂–µ –ø—Ä–∏ –º–∞–ª–µ–Ω—å–∫–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
        wrapped_offset = offset % total_ranked
        page = []
        idx = wrapped_offset
        while len(page) < limit and len(page) < total_ranked:
            page.append(ranked[idx])
            idx = (idx + 1) % total_ranked

        has_more = True  # –∫—Ä—É–≥–æ–≤–∞—è –ª–µ–Ω—Ç–∞ –ø–æ —Å—É—Ç–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–∞
        next_offset = offset + limit
        debug["pagination_mode"] = "wrapped"
        debug["wrapped_offset"] = wrapped_offset

    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    page_source_counts: Dict[str, int] = {}
    page_wiki_count = 0
    for c in page:
        src = (c.get("source_type") or "unknown").lower()
        page_source_counts[src] = page_source_counts.get(src, 0) + 1
        if _is_wikipedia_card(c):
            page_wiki_count += 1
    debug["sources_page"] = page_source_counts
    debug["wiki_count_page"] = page_wiki_count

    debug["returned"] = len(page)
    debug["has_more"] = has_more
    debug["next_offset"] = next_offset

    # 8. –û—Ç–º–µ—á–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–∞–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ
    seen_marked = _mark_cards_as_seen(supabase, user_id, page)
    debug["seen"]["marked"] = int(seen_marked)

    return page, debug


def build_feed_for_user_paginated(
    supabase: Client | None,
    user_id: int,
    limit: int | None = None,
    offset: int = 0,
) -> Tuple[List[Dict[str, Any]], Dict[str, Any], Dict[str, Any]]:
    """
    –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ build_feed_for_user —Å —è–≤–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - items: –∫–∞—Ä—Ç–æ—á–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π "—Å—Ç—Ä–∞–Ω–∏—Ü—ã"
    - debug: –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (reason, base_tags, offset, limit, has_more, ...)
    - cursor: –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ (offset, next_offset, has_more)
    """
    if limit is None or limit <= 0:
        limit = FEED_CARDS_LIMIT_DEFAULT
    limit = min(max(limit, 1), 50)
    offset = max(0, int(offset))

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ —É–º–µ–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å offset/limit
    items, base_debug = build_feed_for_user(
        supabase=supabase,
        user_id=user_id,
        limit=limit,
        offset=offset,
    )

    has_more = bool(base_debug.get("has_more"))
    next_offset = base_debug.get("next_offset")

    cursor: Dict[str, Any] = {
        "limit": limit,
        "offset": offset,
        "next_offset": next_offset,
        "has_more": has_more,
    }

    debug: Dict[str, Any] = {
        **(base_debug or {}),
        "offset": offset,
        "limit": limit,
        "has_more": has_more,
    }

    return items, debug, cursor
